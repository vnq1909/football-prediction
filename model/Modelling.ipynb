{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "96a69c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nbimporter\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from Helper import mapping as mapped_values\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eb4b6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingDict(dict):\n",
    "    __missing__ = lambda self, key: key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0205a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(path):\n",
    "    df_training = pd.read_csv(path, index_col=0)\n",
    "    return df_training\n",
    "\n",
    "def read_test(path):\n",
    "    df_testing = pd.read_csv(path, index_col= 0)\n",
    "    return df_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a32502fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictors(df_train, df_test=None):\n",
    "    df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "\n",
    "    df_train['venue_code'] = df_train['venue'].astype('category').cat.codes\n",
    "    df_train['opp_code'] = df_train['opponent'].astype('category').cat.codes\n",
    "\n",
    "    df_train['hour'] = df_train['time'].str.replace(\":.+\", \"\",regex=True)\n",
    "    df_train['hour'] = df_train['hour'].fillna(df_train['hour'].value_counts().idxmax())\n",
    "\n",
    "    df_train['day_code'] = df_train['date'].dt.dayofweek\n",
    "    df_train['day_code'] = df_train['day_code'].fillna(df_train['day_code'].value_counts().idxmax())\n",
    "\n",
    "    # df_train['target'] = (df_train['result'] == 'W').astype('int')\n",
    "    result_mapping = {'L': 0, 'W': 1, 'D': 2}\n",
    "\n",
    "    df_train['target'] = df_train['result'].map(result_mapping)\n",
    "\n",
    "    if df_test is not None: # Đổi '!= None' thành 'is not None' cho Pythonic hơn\n",
    "        df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "\n",
    "        df_test['venue_code'] = df_test['venue'].astype('category').cat.codes\n",
    "\n",
    "        df_test['opp_code'] = df_test['opponent'].astype('category').cat.codes\n",
    "\n",
    "        df_test['hour'] = df_test['time'].str.replace(\":.+\", \"\",regex=True)\n",
    "        df_test['hour'] = df_test['hour'].fillna(df_test['hour'].value_counts().idxmax())\n",
    "\n",
    "        df_test['day_code'] = df_test['date'].dt.dayofweek\n",
    "\n",
    "        # df_test['target'] = (df_test['result'] == 'W').astype('int')\n",
    "        df_test['target'] = df_test['result'].map(result_mapping)\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3be5a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rolling average for the last 5 games\n",
    "# and replace NaN values with the rolling average.\n",
    "def rolling_averages(group, cols, new_cols):\n",
    "    group = group.sort_values(\"date\")\n",
    "    rolling_stats = group[cols].rolling(5, closed='left').mean()\n",
    "    group[new_cols] = rolling_stats\n",
    "    group = group.dropna(subset=new_cols)\n",
    "    return group\n",
    "\n",
    "def update_with_rolling_average(df, cols, new_cols):\n",
    "    matches_rolling = df.groupby(\"team\").apply(lambda x: rolling_averages(x, cols, new_cols))\n",
    "    matches_rolling = matches_rolling.droplevel('team')\n",
    "    matches_rolling.index = range(matches_rolling.shape[0])\n",
    "    return matches_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d29de03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_ita = \"../Datasets/Cleaned Datasets/Serie_A_Stats_Italy.csv\"\n",
    "url_spain = \"../Datasets/Cleaned Datasets/La_Liga_Stats.csv\"\n",
    "urls = [url_ita, url_spain]\n",
    "def combine(combined, matches_rolling):\n",
    "    combined_data = combined.merge(matches_rolling[['date', 'time', 'team', 'opponent', 'result']],\n",
    "                                   left_index = True, right_index = True)\n",
    "    return combined_data\n",
    "\n",
    "def train_model(data, predictors, url):\n",
    "    rf = RandomForestClassifier(n_estimators=100, min_samples_split=10, random_state=42)\n",
    "\n",
    "    if url == url_spain:\n",
    "        train = data[data[\"date\"] <= '2023-07-19']\n",
    "        test = data[data[\"date\"] > '2023-07-23']\n",
    "    else:\n",
    "        train = data[data[\"date\"] <= '2025-01-02']\n",
    "        test = data[data[\"date\"] > '2025-01-02']\n",
    "\n",
    "    print(f\"Train set size for {url}: {len(train)}\")\n",
    "    print(f\"Test set size for {url}: {len(test)}\")\n",
    "\n",
    "    if len(train) == 0 or len(test) == 0:\n",
    "        print(f\"[ERROR] One of the datasets is empty for: {url}\")\n",
    "        return None, None\n",
    "\n",
    "    rf.fit(train[predictors], train[\"target\"])\n",
    "    preds = rf.predict(test[predictors])\n",
    "    combined = pd.DataFrame(dict(actual=test[\"target\"], predicted=preds), index=test.index)\n",
    "\n",
    "    return rf, combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2b896aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_values(combined_df):\n",
    "\n",
    "    mapping_values = mapped_values() # Gọi hàm mapped_values từ Helper.ipynb\n",
    "\n",
    "    for map_values_dict in mapping_values: # Đổi tên biến để tránh nhầm lẫn với hàm\n",
    "        mapping = MissingDict(**map_values_dict)\n",
    "\n",
    "        combined_df[\"new_team\"] = combined_df[\"team\"].map(mapping)\n",
    "\n",
    "        # Merge DataFrame với chính nó để tạo cặp đấu\n",
    "        merged = combined_df.merge(combined_df, left_on=[\"date\", 'opponent'], right_on=[\"date\", 'new_team'], suffixes=('_x', '_y'))\n",
    "        # Đảm bảo các cột được chọn đúng\n",
    "        merged = merged[['date', 'time_x', 'new_team_x', 'new_team_y', 'predicted_x', 'predicted_y']]\n",
    "\n",
    "        map_string = {0: 'L', 1 : 'W', 2 : 'D'}\n",
    "\n",
    "        merged['new_predicted_x'] = merged['predicted_x'].map(map_string)\n",
    "        merged['new_predicted_y'] = merged['predicted_y'].map(map_string)\n",
    "\n",
    "        renamed_columns = {\n",
    "            'date' : 'Date',\n",
    "            'time_x' : 'Time',\n",
    "            'new_team_x' : 'Team A',\n",
    "            'new_team_y' : 'Team B',\n",
    "            'new_predicted_x' : 'Prediction for Team A',\n",
    "            'new_predicted_y' : 'Prediction for Team B'\n",
    "        }\n",
    "\n",
    "        merged.rename(columns=renamed_columns, inplace=True)\n",
    "\n",
    "        merged = merged.drop(['predicted_x', 'predicted_y'], axis = 1)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c44f4758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_teams(df, url):\n",
    "    # Danh sách các đội cần loại bỏ cho giải Ý\n",
    "    teams_to_drop_ita = [\n",
    "        \"at Rapid Wien\",\n",
    "        \"Reggiana\", \"Parma\",\n",
    "        \"FeralpiSalò\", \"Spezia\",\n",
    "        \"Cosenza\", \"Sampdoria\",\n",
    "        \"Ternana\", \"Pisa\", \"Como\",\n",
    "        \"Ascoli\", \"Modena\", \"Cittadella\",\n",
    "        \"Palermo\", \"Cesena\", \"Catanzaro\"\n",
    "    ]\n",
    "\n",
    "    # Danh sách các đội cần loại bỏ cho giải Tây Ban Nha\n",
    "    teams_to_drop_spain = [\n",
    "        \"Manchester Utd\", \"Bayern Munich\", \"Juventus\", \"Manchester City\", \"Chelsea\", \"Paris S-G\", \"Liverpool\",\n",
    "        \"Leverkusen\", \"Dortmund\", \"Roma\", \"Napoli\", \"Shakhtar\", \"Lyon\", \"PSV Eindhoven\", \"Milan\", \"Ajax\", \"Celtic\",\n",
    "        \"Inter\", \"Porto\", \"Zenit\", \"RB Salzburg\", \"Krasnodar\", \"Sevilla\", \"Sporting CP\", \"Galatasaray\", \"Arsenal\",\n",
    "        \"M'Gladbach\", \"Viktoria Plzeň\", \"Benfica\", \"Club Brugge\", \"Valencia\", \"Monaco\", \"Olympiacos\", \"Panathinaikos\",\n",
    "        \"Loko Moscow\", \"APOEL FC\", \"Ludogorets\", \"Spartak Moscow\", \"Rapid Wien\", \"Dinamo Zagreb\", \"BATE Borisov\",\n",
    "        \"Rennes\", \"Dynamo Kyiv\", \"Basel\", \"Leonesa\", \"Alcoyano\", \"FC Astana\", \"CD Mirandés\", \"Schalke 04\", \"Rijeka\",\n",
    "        \"FC Copenhagen\", \"AZ Alkmaar\", \"Ferencváros\", \"Genk\", \"Mirandés\", \"Rubin Kazan\", \"SD Formentera\", \"Lazio\",\n",
    "        \"Standard Liège\", \"Slavia Prague\", \"Hannover 96\", \"Sparta Prague\", \"Atalanta\", \"Lille\", \"CSKA Moscow\", \"Lleida\",\n",
    "        \"Athletic Club\", \"RB Leipzig\", \"Ponferradina\", \"Eint Frankfurt\", \"Alcorcón\", \"Tenerife\", \"Malmö\", \"Marseille\",\n",
    "        \"Barcelona\", \"Fuenlabrada\", \"Rangers\", \"Young Boys\", \"Ebro\", \"Leicester City\", \"Cornellà\", \"Numancia\", \"Wolves\",\n",
    "        \"Albacete\", \"UD Ibiza\", \"Trabzonspor\", \"CP Cacereño\", \"Real Murcia\", \"CD Arenteiro\", \"Oviedo\", \"AD Ceuta\",\n",
    "        \"Atlético Baleares\", \"Gimnàstic\", \"Zamora CF\", \"Académica\", \"Žalgiris\", \"Sigma Olomouc\", \"Motherwell\",\n",
    "        \"Akhisarspor\", \"Jablonec\", \"Hapoel Tel Aviv\", \"Union Berlin\", \"St. Gallen\", \"Kuban\", \"Swansea City\", \"Lugo\",\n",
    "        \"Újpest\", \"Twente\", \"Helsingborg\", \"Melilla\", \"Betis\", \"Braga\", \"Sant Andreu\", \"Slaven Belupo\", \"Kiryat Shmona\",\n",
    "        \"Antwerp\", \"Stoke City\", \"Strømsgodset\", \"Udinese\", \"Beşiktaş\", \"Luzern\", \"ŠK Slovan Bratislava\", \"Stjarnan\",\n",
    "        \"Qarabağ FK\", \"Steaua\", \"Slovan Liberec\", \"Reus\", \"MŠK Žilina\", \"Inter Baku\", \"Dinamo Minsk\", \"Dinamo\",\n",
    "        \"Hertha BSC\", \"Östersund\", \"Real Jaén\", \"Partizan\", \"Legia Warsaw\", \"Hércules\", \"Rostov\", \"Sassuolo\", \"Guijuelo\",\n",
    "        \"Toledo\", \"Augsburg\", \"FK Vardar\", \"Osmanlıspor\", \"Apollon Limassol\", \"Estoril\", \"Śląsk Wrocław\", \"Mladost\",\n",
    "        \"Aberdeen\", \"Torino\", \"Başakşehir\", \"Fiorentina\", \"Linense\", \"Sabadell\", \"L'Hospitalet\", \"Llagostera\",\n",
    "        \"Rosenborg\", \"Barakaldo\", \"Gent\", \"Freiburg\", \"Odense\", \"Atlético Mancha Real\", \"Intercity\", \"CD Rincón\", \"APOEL\",\n",
    "        \"UD Llanera\", \"CFJ Mollerussa\", \"Aris Limassol FC\", \"Marbella\", \"Maccabi Haifa\", \"Real Unión\", \"Fenerbahçe\",\n",
    "        \"Club Portugalete\", \"Lens\", \"CF La Nucía\", \"Navalcarnero\", \"Sivasspor\", \"CFR Cluj\", \"Pontevedra\", \"West Ham\",\n",
    "        \"Bergantiños FC\", \"Sturm Graz\", \"Hajduk Split\", \"Lech Poznań\", \"Be'er Sheva\", \"CD Guijuelo\", \"FC Andorra\",\n",
    "        \"SD Leioa\", \"Badajoz\", \"Badalona\", \"Unionistas Sal\", \"Sestao\", \"PAOK\", \"Andratx\", \"CF Independiente Alicante\",\n",
    "        \"Majadahonda\", \"Guadalajara\", \"CD L'Alcora\", \"CF Talavera de la Reina\", \"Club Deportivo Atlético Paso\",\n",
    "        \"CF Panadería Pulido\", \"Recreativo\", \"Arenas Club de Getxo\", \"CD Autol\", \"CD Cazalegas\", \"CD Coria\",\n",
    "        \"CD Santa Amalia\", \"Ibiza\", \"CD Fuentes\", \"CD Arnedo\", \"UD Alzira\", \"CD Eldense\", \"Quintanar del Rey\",\n",
    "        \"UD Barbadás\", \"Atlético Saguntino\", \"Velarde CF\", \"Juventud Torremolinos CF\", \"Victoria CF\", \"Gernika Club\",\n",
    "        \"CD San Roque de Lepe\", \"CD Diocesano\", \"Dnipro\", \"CD Algar\", \"Solares SD\", \"Atlético Sanluqueño CF\",\n",
    "        \"CE L'Hospitalet\", \"CD Cantolagua\", \"Peña Deportiva\", \"Racing Rioja CF\", \"Las Rozas CF\", \"UM Escobedo\",\n",
    "        \"Comillas\", \"Orihuela CF\", \"Becerril\", \"UD Sanse\"\n",
    "    ]\n",
    "\n",
    "    # Lấy tên file từ URL để xác định giải đấu\n",
    "    filename = url.split('/')[-1]\n",
    "\n",
    "    # Kiểm tra tên file và loại bỏ các đội tương ứng\n",
    "    if filename == 'Serie_A_Stats_Italy.csv':\n",
    "        df = df[~df['opponent'].isin(teams_to_drop_ita)]\n",
    "    elif filename == 'La_Liga_Stats.csv': # Đã đổi từ Primera_Division_Stats.csv sang La_Liga_Stats.csv\n",
    "        df = df[~df['opponent'].isin(teams_to_drop_spain)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "43edabcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(model, name):\n",
    "    \"\"\"\n",
    "    Hàm này dùng để xuất các model đã được huấn luyện với các tập dữ liệu khác nhau.\n",
    "    Các tham số sử dụng:\n",
    "        - model: model đã được huấn luyện\n",
    "        - name: một biến để xác định từng model. Nó được sử dụng trong hàm main,\n",
    "                và có thể được gán trong mỗi câu lệnh if với tên tương ứng.\n",
    "                Ví dụ: name = \"brazil_serie_a\"\n",
    "    \"\"\"\n",
    "    export = pickle.dump(model, open('../rf_' + name +'.pkl', 'wb'))\n",
    "    return export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "41a0ad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size for ../Datasets/Cleaned Datasets/Serie_A_Stats_Italy.csv: 8179\n",
      "Test set size for ../Datasets/Cleaned Datasets/Serie_A_Stats_Italy.csv: 427\n",
      "Train set size for ../Datasets/Cleaned Datasets/La_Liga_Stats.csv: 8086\n",
      "Test set size for ../Datasets/Cleaned Datasets/La_Liga_Stats.csv: 615\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    url_ita = \"../Datasets/Cleaned Datasets/Serie_A_Stats_Italy.csv\"\n",
    "    url_spain = \"../Datasets/Cleaned Datasets/La_Liga_Stats.csv\"\n",
    "\n",
    "\n",
    "    urls = [url_ita, url_spain]\n",
    "    \n",
    "    for idx, url in enumerate(urls):\n",
    "        \n",
    "        df_train = read_train(url)\n",
    "        \n",
    "        if  url == url_ita or url == url_spain:\n",
    "            df_train = drop_teams(df_train, url)\n",
    "\n",
    "        df_train = create_predictors(df_train)\n",
    "                \n",
    "        cols = [\"gf\", \"ga\", \"sh\", \"sot\", \"pk\", \"pkatt\"]\n",
    "        new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "        matches_rolling = update_with_rolling_average(df_train, cols, new_cols)\n",
    "        \n",
    "        predictors = ['venue_code', 'opp_code', 'hour', 'day_code']\n",
    "        rf_model, combined = train_model(matches_rolling, predictors + new_cols, url)\n",
    "\n",
    "        combined_df = combine(combined, matches_rolling)\n",
    "        # combined_df = combined_df.drop(['actual', 'result'], axis = 1)\n",
    "    \n",
    "        final_df = map_values(combined_df)\n",
    "\n",
    "        # Export the DataFrame to a CSV file\n",
    "\n",
    "        # Xuất DataFrame ra file CSV và model Pickle\n",
    "        if idx == 0: # Giải Ý\n",
    "            final_df.to_csv('../Datasets/Predictions/predictions_serieA_italy.csv', index=False)\n",
    "            export_model(rf_model, \"serieA_italy\")\n",
    "        elif idx == 1: # Giải Tây Ban Nha\n",
    "            final_df.to_csv('../Datasets/Predictions/predictions_laliga_spain.csv', index=False)\n",
    "            export_model(rf_model, \"laliga_spain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb7e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
